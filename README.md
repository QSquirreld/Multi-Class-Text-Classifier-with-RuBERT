# Multi-Class Text Classification with RuBERT

Проект демонстрирует применение предобученной модели **RuBERT** на задаче мультиклассовой классификации оценок фильмов по пользовательским рецензиям из датасета [`blinoff/kinopoisk`](https://huggingface.co/datasets/blinoff/kinopoisk).

## Цель проекта

1. Применить дискриминативную модель для задачи классификации текстов на русском языке.
2. Сравнить два подхода к агрегации эмбеддингов:

- **CLS Pooling** — использование эмбеддинга [CLS]-токена
- **Mean Pooling** — усреднение всех токенов (masked)

## Модель

- `cointegrated/rubert-tiny2` — компактная версия модели RuBERT
- Применяемая модель разделена на 2 части:
  - **Base encoder** (предобученный RuBERT)
  - **Классификатор** — линейный слой, обучаемый на задаче классификации

## Датасет

Используется датасет [`blinoff/kinopoisk`](https://huggingface.co/datasets/blinoff/kinopoisk):

- Содержит пользовательские рецензии фильмов
- Каждая рецензия характеризуется оценкой (от 0 до 10)

## Обучение

- Токенизация: `AutoTokenizer` из Transformers
- Оптимизатор: `AdamW`
- Loss: `CrossEntropyLoss`
- Эпохи: `3`
- Размер батча: `16`
- Метрики: `Accuracy, Precision, Recall, F1-Score`

Модель обучается отдельно с двумя типами pooling-а, чтобы сравнить их эффективность.

## Результаты

| Pooling Method | Accuracy | F1-Score |
|----------------|----------|----------|
| CLS            |  81.58%  |  78.18   |
| Mean           |  81.72%  |  78.82   |


## Структура ноутбука

1. **Загрузка и подготовка данных**
- Предобработка данных датасета
- Разбиение на выборки
- Формирование разделённого датасета
- Токенизация
- Формирование тензорного датасета
2. **Дообучение**
- **Кастомный классификатор** на основе `ruBERT-tiny2` с поддержкой **CLS и Mean pooling**
- `avg_train_and_val()` — обучение или валидация на одной эпохе
- `avg_train()` — главный цикл по эпохам
- `eval_model()` — финальная оценка предсказаний
3. **Сравнение метрик двух подходов**

## Как запустить

1. Установить зависимости:
```bash
pip install transformers datasets scikit-learn torch tqdm
```

2. Запустить ноутбук:
```bash
jupyter notebook Multi_Class_Text_Classifier_with_RuBERT.ipynb
```

## Возможные улучшения

- Добавить графики `loss` и `accuracy` по эпохам для наглядности
- Сохранять обученные модели
- Визуализировать confusion matrix
- Сделать инференс на пользовательском вводе